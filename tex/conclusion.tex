This dissertation has presented three different search-based approaches to control music language models to generate symbolic music with a target perceived emotion. The first approach, described in Chapter \ref{ch:ismir19}, consists of a genetic algorithm to fine-tune a LSTM language model towards generating negative and positive pieces \cite{ferreira_2019}. This approach showed to be successfully in generating positive pieces, but negative pieces were considered slightly ambiguous, according to human evaluators. The second approach is called SBBS and is described in Chapter \ref{ch:aiide20}. It consists of controlling a stochastic beam search algorithm with emotion discriminators that steer the distribution of a language model towards a given emotion \cite{ferreira2020computer}.
A listening test showed that human subjects could correctly identify the emotion of the pieces generated by SBBS as accurately as they were able to identify the emotion of pieces written by humans. The third approach, presented in Chapter \ref{ch:ismir21}, is a monte carlo tree search algorithm that uses PUCT with an emotion discriminator to search for music pieces with a target emotion. According to a listening test, MCTS outperformed SBBS in terms of quality and has slightly better accuracy when controlling emotions.

A dataset of symbolic music called VGMIDI has been created to support these three approaches. VGMIDI has 200  pieces labeled according to the circumplex model of emotion \cite{russell1980circumplex} and 3,640 unlabelled ones, where all of them are piano arrangements of video game soundtracks. The labeling process was performed by 30 annotators with a custom web tool designed as part of this dissertation. Moreover, this dissertation also presented Bardo Composer, a system to generate music for tabletop roleplaying games. Bardo Composer uses a speech recognition system to translate player speech into text, which is classified according to a model of emotion. Bardo Composer then uses SBBS with a neural model to generate musical pieces conveying the desired emotion.

The contributions of this dissertation showed that combining neural LMs with search methods has strong potential in generating music with controllable emotion. As discussed in Chapter \ref{ch:future}, there are several possibilities of future work, from increasing the VGMIDI dataset to developing new neural models and applying Bardo Composer to other media (e.g., video games and films). Hopefully, the ideas discussed in this dissertation will inspire others to explore some of this future work and other ideas that will allow neural models to generate music with human level quality.
